{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Numpy2AD Tutorial\n",
    "## Generating Adjoint Code for Numpy Matrix Expressions\n",
    "\n",
    "In this tutorial notebook we will present some basic examples on how to use **Numpy2AD**.\n",
    "\n",
    "The motivation for this package is the following: matrix expressions can be understood high-dimensional functions. For example, a simple **matrix-vector product** takes $ n \\times m$ (the matrix) plus $m$ (the vector) **inputs** to compute $n$ **outputs**. We are interested in the partial derivatives of **each output** with respect to **all inputs** (the Jacobian tensor). Naive [finite differences](https://en.wikipedia.org/wiki/Finite_difference_method) would require us to perform as many \"forward\" passes (expression evaluations) as there are input entries. In [adjoint (reverse) mode algorithmic differentiation](https://en.wikipedia.org/wiki/Automatic_differentiation#Reverse_accumulation), **only $n$** combined forward and backwards passes are needed. Clearly, $O(n)$ scales much better than $O(mn + m)$ for larger and larger problem sizes. \n",
    "\n",
    "Numpy2AD applies the method of **source-to-source** transformation to generate adjoint code for matrix expressions that contain any permutation of **addition, multiplication, transposing,** and **inverting**. By using this package you can benefit from transparently **readable and understandable** derivative code for your sensitivity analysis and optimzation problems. The generated code can be easily pasted into a script or imported as a module. Importantly, there is no runtime overhead compared to other autodiff frameworks, e.g. jax or pytorch, and no new syntax to learn."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ast\n",
    "import numpy as np\n",
    "from numpy2ad import draw_AST, transform, transform_expr"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1st Example: Transforming an Expression\n",
    "\n",
    "We use the `@` operator as shorthand for m**at**mul (matrix multiplication). This allows for a more natural, math-like syntax.\n",
    "\n",
    "First, let us explore the expression tree, also referred to as *abstract syntax tree* (AST), of a simple **matrix-matrix multiplication** and **addition**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dump the native ast\n",
    "print(ast.dump(ast.parse(\"D = A @ B + C\"), indent=3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you can see, the expression is a nested structure essentially composed of one *Assign* and two *BinOp*s (binary operations).\n",
    "\n",
    "With Numpy2AD's `draw_AST` we can get a graphical representation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dot graph for AST\n",
    "draw_AST(\"D = A @ B + C\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let us transform the expression to adjoint code.\n",
    "\n",
    "Essentially, the AST is first *linearized* into *single-assignment code* by introducing intermediate variables `v{i}`. Partial derivatives of each assignment are then generated and appended in reverse order."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "print(transform_expr(\"Y = A @ B + C\"))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note how adjoints (suffix `_a`) are always incremented to allow for correct derivative propagation.\n",
    "\n",
    "To use this code we must import numpy and correctly seed the adjoint variables. Below we calculate the adjoint of the first entry in `Y`. Remember that accumulating the full Jacobian will require a loop over all outputs (not shown here)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dims = (3, 3)\n",
    "A = np.ones(dims)\n",
    "A_a = np.zeros(dims)  # dYdA\n",
    "B = np.full(dims, 2.0)\n",
    "B_a = np.zeros(dims)  # dYdB\n",
    "C = np.full(dims, 3.0)\n",
    "C_a = np.zeros(dims)  # dYdC\n",
    "Y_a = np.zeros(dims)\n",
    "Y_a[0, 0] = 1  # adjoint seed\n",
    "\n",
    "# adjoint code\n",
    "v0 = A @ B\n",
    "Y = v0 + C\n",
    "v0_a = np.zeros(v0.shape)\n",
    "C_a += Y_a\n",
    "v0_a += Y_a\n",
    "B_a += A.T @ v0_a\n",
    "A_a += v0_a @ B.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Y =\\n {Y}\\ndY/dA = \\n {A_a}\\ndY/dB =\\n {B_a}\\ndY/dC =\\n {C_a}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The results can be easily verified: the first entry in `Y` is, by the rules of matrix-matrix products, the inner product of the first **row** of `A` and the first **column** of `B` plus the first entry in `C`. Therefore, the partial derivatives with respect to the input matrices are nonzero in exactly those entries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# AST of transformed expression\n",
    "draw_AST(transform_expr(\"D = A @ B + C\"))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2nd Example: Transforming a Function\n",
    "\n",
    "We define a simple Python function `simple_func` that computes the same matrix expression as above and apply Numpy2AD's `transform` method to it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def simple_func(A, B, C):\n",
    "    return A @ B + C"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "simple_func_transformed = transform(simple_func)\n",
    "print(simple_func_transformed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The result is a string in which the corresponding *adjoint function* is defined. \n",
    "\n",
    "Some things to note here:\n",
    "- The function name is automatically extended with `_ad` and adjoints of function arguments (`A_a`, `B_a`, ...) and output (`out_a`) are appended.\n",
    "- The result of the original function is returned as `out` in the first entry of the return tuple. All adjoint varibles follow.\n",
    "- Adjoints of all intermediate variables `v{i}` are zero-initialized.\n",
    "- Numpy is automatically imported.\n",
    "\n",
    "The `transform` method has an optional argument called `out_file` with which the adjoint function can be conveniently exported as a Python module. If you wish to immediately use the function, it must first be compiled to a code object, as shown below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Compile and execute it to make it visible\n",
    "exec(compile(simple_func_transformed, filename=\"<ast>\", mode=\"exec\"))\n",
    "\n",
    "# active arguments\n",
    "dims = (3, 3)\n",
    "A = 1.5 * np.ones(dims)\n",
    "B = 2.0 * np.ones(dims)\n",
    "C = 3.0 * np.ones(dims)\n",
    "# initialize adjoints\n",
    "A_a = np.zeros(dims)\n",
    "B_a = np.zeros(dims)\n",
    "C_a = np.zeros(dims)\n",
    "Y_a = np.zeros(dims)\n",
    "# seed the adjoint direction\n",
    "Y_a[0][0] = 1\n",
    "\n",
    "result, A_a, B_a, C_a = simple_func_ad(A, B, C, A_a, B_a, C_a, Y_a)\n",
    "print(f\"primal result:\\n {result}\\n dy/dA:\\n {A_a}\\n dy/dB:\\n {B_a}\\n dy/dC:\\n {C_a}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3rd Example: A Real Use Case\n",
    "\n",
    "Consider the [*Generalized Least Squares*](https://en.wikipedia.org/wiki/Generalized_least_squares) problem (GLS). The goal is to estimate regression coefficients $b$ from observations $y$ with design matrix $X$ and error covariance matrix $M$. The derivatives will tells us how e.g. the coefficients depends on the observations (uncertain) or model parameters.\n",
    "\n",
    "We choose a simple linear model: $y_i = \\beta_0 + \\beta_1 \\, x_i$ with measurement error covariance: $\\sigma_i^2 = 0.01 + \\alpha \\, x_i$. For $\\alpha \\neq 0$ the problem become *heteroscedastic*, essentially meaning that the uncertainty increases proportionally to the magnitude of $x$.\n",
    "\n",
    "Below is an implementation of the closed-form solution to the GLS problem and its corresponding adjoint code for sensitivity analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def GLS(X, M, y):\n",
    "    M_inv = np.linalg.inv(M)\n",
    "    return np.linalg.inv(X.T @ M_inv @ X) @ X.T @ M_inv @ y\n",
    "\n",
    "GLS_ad_str = transform(GLS)\n",
    "print(GLS_ad_str)\n",
    "\n",
    "exec(compile(GLS_ad_str, filename=\"<ast>\", mode=\"exec\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Noise-free Case\n",
    "\n",
    "We are interested in the sensitivity (partial derivatives) of the slope parameter `b[1]` with respect to all measurements. This will tell us how \"important\" individual data points are."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "N = 100\n",
    "K = 2\n",
    "\n",
    "# Construct the covariance matrix\n",
    "def build_system(alpha):\n",
    "    x = np.linspace(0, 1, N)  # x from 0 to 1\n",
    "    var = 0.01 + alpha * x # variances\n",
    "    cov_mat = np.zeros((N, N))\n",
    "    np.fill_diagonal(cov_mat, var)  # no cross-correlations terms\n",
    "    samples = (x + np.random.multivariate_normal(\n",
    "        mean=np.zeros(N), cov=cov_mat)).reshape((N, 1))\n",
    "    return x, samples, cov_mat\n",
    "\n",
    "# plot measurements and ground truth\n",
    "x, samples, cov_mat = build_system(alpha=0.0)\n",
    "\n",
    "plt.figure(figsize=(5, 5))\n",
    "plt.plot(x, samples, \".\")\n",
    "plt.plot(x, x, \"r--\", label=\"y=x\")\n",
    "plt.xlabel(\"$x$\")\n",
    "plt.ylabel(\"$y(x)$\")\n",
    "plt.legend();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize\n",
    "y = samples\n",
    "y_a = np.zeros_like(samples)\n",
    "X = np.ones((N, K))\n",
    "X[:, 1] = x\n",
    "X_a = np.zeros_like(X)\n",
    "M = cov_mat\n",
    "M_a = np.zeros_like(M)\n",
    "\n",
    "b_a = np.zeros((K, 1))\n",
    "b_a[1] = 1  # differentiate w.r.t slope parameter of regression\n",
    "\n",
    "b, X_a, M_a, y_a = GLS_ad(X, M, y, X_a, M_a, y_a, b_a)\n",
    "print(b)  # should be close to [0, 1] (an ideal linear slope)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let us plot the entries in the gradient."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(5, 5))\n",
    "plt.plot(y_a, \".\")\n",
    "plt.xlabel(\"$i$\")\n",
    "plt.ylabel(r\"$\\nabla_y \\, b_1(i)$\")\n",
    "plt.title(\"Gradient magnitude: \" + f\"{np.linalg.norm(y_a): .3f}\");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that \"early\" and \"late\" samples contribute equally. The zero-crossing happens at exactly the midpoint sample."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Noisy Case\n",
    "\n",
    "Now let us add some heteroscedastic noise to the measurements and see how the sensitivities change."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x, samples, cov_mat = build_system(alpha=0.1)\n",
    "plt.figure(figsize=(5, 5))\n",
    "plt.plot(x, samples, \".\")\n",
    "plt.plot(x, x, \"r--\", label=\"y=x\")\n",
    "plt.xlabel(\"$x$\")\n",
    "plt.ylabel(\"$y(x)$\")\n",
    "plt.legend();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize\n",
    "y = samples\n",
    "y_a = np.zeros(samples.shape)\n",
    "X = np.ones((N, K))\n",
    "X[:, 1] = x\n",
    "X_a = np.zeros_like(X)\n",
    "M = cov_mat\n",
    "M_a = np.zeros_like(M)\n",
    "\n",
    "b_a = np.zeros((K, 1))\n",
    "\n",
    "b, X_a, M_a, y_a = GLS_ad(X, M, y, X_a, M_a, y_a, b_a)\n",
    "print(b) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(5, 5))\n",
    "plt.plot(y_a)\n",
    "plt.xlabel(\"$i$\")\n",
    "plt.ylabel(r\"$\\nabla_y \\, b_1(i)$\")\n",
    "plt.title(\"Gradient magnitude: \" + f\"{np.linalg.norm(y_a): .3f}\");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Clearly, early samples contribute nonlinearly more than later ones! \n",
    "\n",
    "This insight to the GLS model might be intuitive to some but with Numpy2AD's adjoint transformation it can be clearly shown in code. There are many more effects to analyze here but that is beyond the scope of this tutorial.\n",
    "\n",
    "If you have any questions, please feel free to reach out to us on GitHub."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "18e6e4eb0a4d7cb24cb51759c4dfed13436bbee075f5c6c6284d16f19e522559"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
